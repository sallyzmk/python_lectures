---
title: "시각화 복습 정리"
date: '2022-07-06 01:00'
---

# 0. 자율학습
- [그래프]
https://seaborn.pydata.org/tutorial.html
- [색상값]
https://matplotlib.org/stable/tutorials/colors/colormaps.html

# 데이터 분석 (머신러닝, 딥러닝) 프로세스
- 1. 데이터 불러오기
  + csv, 오라클, MySQL, PostgreSQL, 클라우드 DB 연동
- 2. 데이터 탐색적 자료 분석
  + 데이터 전처리 -> 시각화 -> 데이터 전처리 -> 시각화 반복
- 3. 잠정적인 컬럼의 갯수를 지정하야 함. (pca)
- 4. 머신러닝 모델 (=통계 모델링, t.test, 분산분석, 교차분석)
- 5. 머신러닝 모델의 경우 -> 배포 (현재로서는 X)
  + JSP-스프링 웹개발시, 배우게 된다.
- 6. 통계 모델링의 경우, p-value 값 기준으로, 귀무가설 및 대립가설 검정
- 7. (머신러닝, 딥러닝 공통) 결과 보고서를 작성해야 함.
  + PPT 만들어야 함.
  + 사기업은 매출로 인증

# 그래프 복습
- 수치형 데이터 시각화
- 범주형 데이터 시각화
- 데이터 관계 시각화
- matplotlib 라이브러리 방법(복잡)
- seaborn 라이브러리 방법(단순)
  + 복작합 그래프 그려야지!! --> matpltoltib
  + 1줄 그래프 --> seaborn

# 수치형 데이터 시각화


```python
import seaborn as sns
titanic = sns.load_dataset('titanic')
titanic.head()
# print(titanic.head())
# 수치형 데이터인지 문자형 데이터인지, 이분법인지 연속성데이터인지
```





  <div id="df-1344c706-e32a-4f70-abbc-5585e3304147">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>survived</th>
      <th>pclass</th>
      <th>sex</th>
      <th>age</th>
      <th>sibsp</th>
      <th>parch</th>
      <th>fare</th>
      <th>embarked</th>
      <th>class</th>
      <th>who</th>
      <th>adult_male</th>
      <th>deck</th>
      <th>embark_town</th>
      <th>alive</th>
      <th>alone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Cherbourg</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>S</td>
      <td>Third</td>
      <td>woman</td>
      <td>False</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>S</td>
      <td>First</td>
      <td>woman</td>
      <td>False</td>
      <td>C</td>
      <td>Southampton</td>
      <td>yes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>S</td>
      <td>Third</td>
      <td>man</td>
      <td>True</td>
      <td>NaN</td>
      <td>Southampton</td>
      <td>no</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1344c706-e32a-4f70-abbc-5585e3304147')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1344c706-e32a-4f70-abbc-5585e3304147 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1344c706-e32a-4f70-abbc-5585e3304147');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['images/visualization_review/output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




## 히스토그램
- ggplot와 식이 비슷함, 간단한데 그래프가 잘 나옴.


```python
# bins =10 : 10으로 나누자,
# hue ='alive' : 살았냐 안살았냐
sns.histplot(data = titanic, x='age', bins =10, hue ='alive', multiple = 'stack')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb544f04110>




    
![png](images/visualization_review/output_7_1.png)
    


- 위 그래프를 통하여 ~~~ : 그래프에 대한 설명 추가

## 커널밀도추정 함수 그래프
- 연속형 데이터 1개만 쓸 때 사용
- 분포를 알아볼 때 사용


```python
sns.kdeplot(data = titanic, x ='age', hue = 'alive', multiple= 'stack')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb544e00450>




    
![png](images/visualization_review/output_10_1.png)
    


## 분포도
- 수치형 데이터 한개 컬럼의 분포를 나타내는 그래프
- 정규분포인가?
- 비정규분포(치우침)


```python
sns.displot(data = titanic, x='age', kde = True)
```




    <seaborn.axisgrid.FacetGrid at 0x7fb542d3c150>




    
![png](images/visualization_review/output_12_1.png)
    


# 범주형 데이터 시각화
- x축 범주형, y축 수치 데이터
- x축 범주형, y축 범주형
  + 히트맵

## 막대 그래프


```python
sns.barplot(x = 'class', y='fare', data=titanic)
# error bar : 오차 막대
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb54038bf90>




    
![png](images/visualization_review/output_15_1.png)
    


## 포인트 플롯


```python
sns.pointplot(x='class', y='fare', data=titanic)
# 강사님 블로그에 사이즈 변경하는 방법 나옴....그래프 까야됨.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb54038ba50>




    
![png](images/visualization_review/output_17_1.png)
    


## 박스 플롯
- 제1사 분위 : 전체 데이터 중 하위 2%
- 사분위 범위 수(IQR) : 제 3사분위 - 제 1사분위
- 최댓값: 제 3사분위 + (1.5 * IQR)


```python
# boxplot
sns.boxplot(x='class',y='age', data=titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb54028dc50>




    
![png](images/visualization_review/output_19_1.png)
    


## 바이올린 플롯


```python
sns.violinplot(x='class', y='age', hue='sex',data=titanic, split=True);
```


    
![png](images/visualization_review/output_21_0.png)
    


## 카운트 플롯 (범주형 데이터만)
- 범주형 데이터의 갯수 확인 할 때 사용


```python
sns.countplot(x='alive', data=titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb5401965d0>




    
![png](images/visualization_review/output_23_1.png)
    


# 데이터 관계 시각화
- 여러 데이터 사이의 관계도 파악 위한 그래프

## 히트맵


```python
flights = sns.load_dataset('flights')
# flights.head()
print(flights.head())
```

       year month  passengers
    0  1949   Jan         112
    1  1949   Feb         118
    2  1949   Mar         132
    3  1949   Apr         129
    4  1949   May         121
    

- 각 연도별, 월별 승객수 구하기


```python
flights['year'].value_counts()
```




    1949    12
    1950    12
    1951    12
    1952    12
    1953    12
    1954    12
    1955    12
    1956    12
    1957    12
    1958    12
    1959    12
    1960    12
    Name: year, dtype: int64



### pivot() Pivot Tables (피봇 테이블) 만드는 법


```python
# 피벗 만드는 방법
# 코드를 판다스 튜토리얼에서 나온대로 입력 -> 이해 -> 적용
import pandas as pd
df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
                           'two'],
                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
                   'baz': [1, 2, 3, 4, 5, 6],
                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
df
```





  <div id="df-0a0646f2-2e34-4e11-9cf8-81b372e31345">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>foo</th>
      <th>bar</th>
      <th>baz</th>
      <th>zoo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>one</td>
      <td>A</td>
      <td>1</td>
      <td>x</td>
    </tr>
    <tr>
      <th>1</th>
      <td>one</td>
      <td>B</td>
      <td>2</td>
      <td>y</td>
    </tr>
    <tr>
      <th>2</th>
      <td>one</td>
      <td>C</td>
      <td>3</td>
      <td>z</td>
    </tr>
    <tr>
      <th>3</th>
      <td>two</td>
      <td>A</td>
      <td>4</td>
      <td>q</td>
    </tr>
    <tr>
      <th>4</th>
      <td>two</td>
      <td>B</td>
      <td>5</td>
      <td>w</td>
    </tr>
    <tr>
      <th>5</th>
      <td>two</td>
      <td>C</td>
      <td>6</td>
      <td>t</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0a0646f2-2e34-4e11-9cf8-81b372e31345')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0a0646f2-2e34-4e11-9cf8-81b372e31345 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0a0646f2-2e34-4e11-9cf8-81b372e31345');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['images/visualization_review/output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
df.pivot(index='foo', columns='bar', values='baz')
```





  <div id="df-0e2601f4-c5cb-44ce-999f-9807879e477e">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>bar</th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
    <tr>
      <th>foo</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>one</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>two</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0e2601f4-c5cb-44ce-999f-9807879e477e')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0e2601f4-c5cb-44ce-999f-9807879e477e button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0e2601f4-c5cb-44ce-999f-9807879e477e');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['images/visualization_review/output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
flights_pivot = flights.pivot(index = 'month', columns= 'year' , values='passengers')
flights_pivot
# 어디가 많고 적인지 직관적이게 안보인다.
```





  <div id="df-3b2f007f-2107-4d2f-9f91-f507488b3d8c">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>year</th>
      <th>1949</th>
      <th>1950</th>
      <th>1951</th>
      <th>1952</th>
      <th>1953</th>
      <th>1954</th>
      <th>1955</th>
      <th>1956</th>
      <th>1957</th>
      <th>1958</th>
      <th>1959</th>
      <th>1960</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Jan</th>
      <td>112</td>
      <td>115</td>
      <td>145</td>
      <td>171</td>
      <td>196</td>
      <td>204</td>
      <td>242</td>
      <td>284</td>
      <td>315</td>
      <td>340</td>
      <td>360</td>
      <td>417</td>
    </tr>
    <tr>
      <th>Feb</th>
      <td>118</td>
      <td>126</td>
      <td>150</td>
      <td>180</td>
      <td>196</td>
      <td>188</td>
      <td>233</td>
      <td>277</td>
      <td>301</td>
      <td>318</td>
      <td>342</td>
      <td>391</td>
    </tr>
    <tr>
      <th>Mar</th>
      <td>132</td>
      <td>141</td>
      <td>178</td>
      <td>193</td>
      <td>236</td>
      <td>235</td>
      <td>267</td>
      <td>317</td>
      <td>356</td>
      <td>362</td>
      <td>406</td>
      <td>419</td>
    </tr>
    <tr>
      <th>Apr</th>
      <td>129</td>
      <td>135</td>
      <td>163</td>
      <td>181</td>
      <td>235</td>
      <td>227</td>
      <td>269</td>
      <td>313</td>
      <td>348</td>
      <td>348</td>
      <td>396</td>
      <td>461</td>
    </tr>
    <tr>
      <th>May</th>
      <td>121</td>
      <td>125</td>
      <td>172</td>
      <td>183</td>
      <td>229</td>
      <td>234</td>
      <td>270</td>
      <td>318</td>
      <td>355</td>
      <td>363</td>
      <td>420</td>
      <td>472</td>
    </tr>
    <tr>
      <th>Jun</th>
      <td>135</td>
      <td>149</td>
      <td>178</td>
      <td>218</td>
      <td>243</td>
      <td>264</td>
      <td>315</td>
      <td>374</td>
      <td>422</td>
      <td>435</td>
      <td>472</td>
      <td>535</td>
    </tr>
    <tr>
      <th>Jul</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>230</td>
      <td>264</td>
      <td>302</td>
      <td>364</td>
      <td>413</td>
      <td>465</td>
      <td>491</td>
      <td>548</td>
      <td>622</td>
    </tr>
    <tr>
      <th>Aug</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>242</td>
      <td>272</td>
      <td>293</td>
      <td>347</td>
      <td>405</td>
      <td>467</td>
      <td>505</td>
      <td>559</td>
      <td>606</td>
    </tr>
    <tr>
      <th>Sep</th>
      <td>136</td>
      <td>158</td>
      <td>184</td>
      <td>209</td>
      <td>237</td>
      <td>259</td>
      <td>312</td>
      <td>355</td>
      <td>404</td>
      <td>404</td>
      <td>463</td>
      <td>508</td>
    </tr>
    <tr>
      <th>Oct</th>
      <td>119</td>
      <td>133</td>
      <td>162</td>
      <td>191</td>
      <td>211</td>
      <td>229</td>
      <td>274</td>
      <td>306</td>
      <td>347</td>
      <td>359</td>
      <td>407</td>
      <td>461</td>
    </tr>
    <tr>
      <th>Nov</th>
      <td>104</td>
      <td>114</td>
      <td>146</td>
      <td>172</td>
      <td>180</td>
      <td>203</td>
      <td>237</td>
      <td>271</td>
      <td>305</td>
      <td>310</td>
      <td>362</td>
      <td>390</td>
    </tr>
    <tr>
      <th>Dec</th>
      <td>118</td>
      <td>140</td>
      <td>166</td>
      <td>194</td>
      <td>201</td>
      <td>229</td>
      <td>278</td>
      <td>306</td>
      <td>336</td>
      <td>337</td>
      <td>405</td>
      <td>432</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-3b2f007f-2107-4d2f-9f91-f507488b3d8c')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-3b2f007f-2107-4d2f-9f91-f507488b3d8c button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-3b2f007f-2107-4d2f-9f91-f507488b3d8c');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['images/visualization_review/output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
sns.heatmap(data = flights_pivot)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb53fe51450>




    
![png](images/visualization_review/output_33_1.png)
    


## 라인플롯


```python
sns.lineplot(x='year', y='passengers', data = flights)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb53fd75750>




    
![png](images/visualization_review/output_35_1.png)
    


## 산점도


```python
tips = sns.load_dataset('tips')
# tips.head()
print(tips.head())
```





  <div id="df-d6561988-7c33-4c45-9ae2-8e33a8ee44fd">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>sex</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16.99</td>
      <td>1.01</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.34</td>
      <td>1.66</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21.01</td>
      <td>3.50</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.68</td>
      <td>3.31</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24.59</td>
      <td>3.61</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-d6561988-7c33-4c45-9ae2-8e33a8ee44fd')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-d6561988-7c33-4c45-9ae2-8e33a8ee44fd button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-d6561988-7c33-4c45-9ae2-8e33a8ee44fd');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['images/visualization_review/output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




- 두개의 연속형 데이터
  + size는 카운트데이터이지 연속형 데이터는 아니다


```python
sns.scatterplot(x='total_bill', y='tip', hue = 'time', data= tips)
# 점심 보다 저녁에 팁을 더 높게 준다.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb540196a10>




    
![png](images/visualization_review/output_39_1.png)
    



```python
sns.scatterplot(x='total_bill', y='tip', hue = 'sex', data= tips)
# 왜 여자가 남자보다 팁을 더 적게 줄까?
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb5404093d0>




    
![png](images/visualization_review/output_40_1.png)
    


## 회귀선


```python
sns.regplot(x= 'total_bill', y='tip', data=tips)
# 정확한 수치를 알고 싶다면 기울기를 알아야 한다.
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb53fc0fa10>




    
![png](images/visualization_review/output_42_1.png)
    


# 머신러닝 리뷰 
- 가장 인기 있는 모델 
  + LightGBM,. XGboost

## 선형 회귀
- 선형 회귀식을 찾는 것이 중요
- $y = 3x + 4$에 근사한 데이터 50개 생성


```python
import numpy as np
import pandas as pd

# 시드값 고정
np.random.seed(0)
intercept = 4 # 절편, 상수
slope = 3 # 기울기

# 변동성 주기 위해 노이즈 생성
noise = np.random.randn(50,1)
x=5* np.random.rand(50,1) # 0과 5 사이의 실숫값 50개 생성
y = slope * x + intercept + noise

# 데이터 프레임 생성
data = pd.DataFrame({'X': x[:,0], 'Y': y[:,0]})
print(data)
```

               X          Y
    0   0.794848   8.148596
    1   0.551876   6.055784
    2   3.281648  14.823682
    3   0.690915   8.313637
    4   0.982912   8.816293
    5   1.843626   8.553600
    6   4.104966  17.264987
    7   0.485506   5.305162
    8   4.189725  16.465955
    9   0.480492   5.852075
    10  4.882297  18.790936
    11  2.343256  12.484042
    12  4.883805  19.412454
    13  3.024228  13.194358
    14  3.696318  15.532817
    15  0.195939   4.921491
    16  1.414035   9.736184
    17  0.600983   5.597790
    18  1.480701   8.755171
    19  0.593639   4.926820
    20  1.589916   6.216758
    21  2.071315  10.867564
    22  0.320737   5.826649
    23  3.462361  13.644917
    24  2.833007  14.768776
    25  1.326947   6.526477
    26  2.616240  11.894479
    27  0.469703   5.221924
    28  2.879732  14.171977
    29  4.646481  19.408802
    30  1.592845   8.933482
    31  3.337052  14.389318
    32  0.658989   5.089182
    33  3.581636  12.764112
    34  1.447030   7.993179
    35  0.915957   6.904219
    36  2.932565  14.027985
    37  0.100538   5.503993
    38  4.144700  16.046774
    39  0.023477   3.768129
    40  3.389083  13.118695
    41  1.350040   6.630102
    42  3.675970  13.321640
    43  4.810943  20.383604
    44  1.243766   7.221645
    45  2.880787  12.204286
    46  2.960210  11.627834
    47  2.861260  13.361269
    48  1.115408   5.732327
    49  4.763745  18.078495
    





  <div id="df-5f1cdf6e-a2cc-43eb-8402-b062efbc280a">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.794848</td>
      <td>8.148596</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.551876</td>
      <td>6.055784</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.281648</td>
      <td>14.823682</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.690915</td>
      <td>8.313637</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.982912</td>
      <td>8.816293</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.843626</td>
      <td>8.553600</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.104966</td>
      <td>17.264987</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.485506</td>
      <td>5.305162</td>
    </tr>
    <tr>
      <th>8</th>
      <td>4.189725</td>
      <td>16.465955</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.480492</td>
      <td>5.852075</td>
    </tr>
    <tr>
      <th>10</th>
      <td>4.882297</td>
      <td>18.790936</td>
    </tr>
    <tr>
      <th>11</th>
      <td>2.343256</td>
      <td>12.484042</td>
    </tr>
    <tr>
      <th>12</th>
      <td>4.883805</td>
      <td>19.412454</td>
    </tr>
    <tr>
      <th>13</th>
      <td>3.024228</td>
      <td>13.194358</td>
    </tr>
    <tr>
      <th>14</th>
      <td>3.696318</td>
      <td>15.532817</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.195939</td>
      <td>4.921491</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.414035</td>
      <td>9.736184</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.600983</td>
      <td>5.597790</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1.480701</td>
      <td>8.755171</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.593639</td>
      <td>4.926820</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1.589916</td>
      <td>6.216758</td>
    </tr>
    <tr>
      <th>21</th>
      <td>2.071315</td>
      <td>10.867564</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.320737</td>
      <td>5.826649</td>
    </tr>
    <tr>
      <th>23</th>
      <td>3.462361</td>
      <td>13.644917</td>
    </tr>
    <tr>
      <th>24</th>
      <td>2.833007</td>
      <td>14.768776</td>
    </tr>
    <tr>
      <th>25</th>
      <td>1.326947</td>
      <td>6.526477</td>
    </tr>
    <tr>
      <th>26</th>
      <td>2.616240</td>
      <td>11.894479</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.469703</td>
      <td>5.221924</td>
    </tr>
    <tr>
      <th>28</th>
      <td>2.879732</td>
      <td>14.171977</td>
    </tr>
    <tr>
      <th>29</th>
      <td>4.646481</td>
      <td>19.408802</td>
    </tr>
    <tr>
      <th>30</th>
      <td>1.592845</td>
      <td>8.933482</td>
    </tr>
    <tr>
      <th>31</th>
      <td>3.337052</td>
      <td>14.389318</td>
    </tr>
    <tr>
      <th>32</th>
      <td>0.658989</td>
      <td>5.089182</td>
    </tr>
    <tr>
      <th>33</th>
      <td>3.581636</td>
      <td>12.764112</td>
    </tr>
    <tr>
      <th>34</th>
      <td>1.447030</td>
      <td>7.993179</td>
    </tr>
    <tr>
      <th>35</th>
      <td>0.915957</td>
      <td>6.904219</td>
    </tr>
    <tr>
      <th>36</th>
      <td>2.932565</td>
      <td>14.027985</td>
    </tr>
    <tr>
      <th>37</th>
      <td>0.100538</td>
      <td>5.503993</td>
    </tr>
    <tr>
      <th>38</th>
      <td>4.144700</td>
      <td>16.046774</td>
    </tr>
    <tr>
      <th>39</th>
      <td>0.023477</td>
      <td>3.768129</td>
    </tr>
    <tr>
      <th>40</th>
      <td>3.389083</td>
      <td>13.118695</td>
    </tr>
    <tr>
      <th>41</th>
      <td>1.350040</td>
      <td>6.630102</td>
    </tr>
    <tr>
      <th>42</th>
      <td>3.675970</td>
      <td>13.321640</td>
    </tr>
    <tr>
      <th>43</th>
      <td>4.810943</td>
      <td>20.383604</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1.243766</td>
      <td>7.221645</td>
    </tr>
    <tr>
      <th>45</th>
      <td>2.880787</td>
      <td>12.204286</td>
    </tr>
    <tr>
      <th>46</th>
      <td>2.960210</td>
      <td>11.627834</td>
    </tr>
    <tr>
      <th>47</th>
      <td>2.861260</td>
      <td>13.361269</td>
    </tr>
    <tr>
      <th>48</th>
      <td>1.115408</td>
      <td>5.732327</td>
    </tr>
    <tr>
      <th>49</th>
      <td>4.763745</td>
      <td>18.078495</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-5f1cdf6e-a2cc-43eb-8402-b062efbc280a')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-5f1cdf6e-a2cc-43eb-8402-b062efbc280a button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-5f1cdf6e-a2cc-43eb-8402-b062efbc280a');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['images/visualization_review/output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
import matplotlib.pyplot as plt
fig, ax = plt.subplots()
ax.scatter(data['X'], data['Y'])
plt.show()
```


    
![png](images/visualization_review/output_46_0.png)
    



```python
import seaborn as sns 
sns.scatterplot(x = 'X', y = 'Y', data = data)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fb53f5fe490>




    
![png](images/visualization_review/output_47_1.png)
    


## 선형 회귀 모형 훈련
- 모형 생성 후, 회귀계수 3과 y절편 4에 근사한 값이 나와야 함.


```python
from sklearn.linear_model import LinearRegression
lr_model = LinearRegression() #선형 회귀 모델
lr_model.fit(x,y) # 모델 훈련

print('y절편:', lr_model.intercept_)
print('회귀계수:', lr_model.coef_)
```

    y절편: [4.05757639]
    회귀계수: [[3.03754061]]
    


```python
# 예측값
y_pred = lr_model.predict(x)
fig, ax = plt.subplots()
ax.scatter(x, y)
ax.plot(x, y_pred, color='green')

# slope, intercept 
label = 'slope: {}\nintercept: {}'.format(round(lr_model.coef_[0][0], 2), round(lr_model.intercept_[0], 2))
ax.text(3.5, 4, label, style ='italic', 
        fontsize = 10, color ="green")
plt.show()
```


    
![png](images/visualization_review/output_50_0.png)
    


### 로지스틱 회귀


```python
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(arr, scale=1):
    arr = np.asarray(arr)
    result = 1/(1 + np.exp(-arr*scale))
    return result

x = np.linspace(-6, 6)
y = sigmoid(x)

fig, ax = plt.subplots()
ax.plot(x, y)
ax.grid(which='major', axis='y', linestyle='--')
ax.axvline(x=0, color='r', linestyle='--', linewidth=1)
ax.set_ylim(0,1)
ax.set_yticks([0, 1, 0.5])
ax.text(0-0.1, 0.5, '0.5', ha='right')
ax.set_title('Sigmoid Graph')
plt.show()
```


    
![png](images/visualization_review/output_52_0.png)
    



```python
# 라이브러리 불러오기
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# 데이터 가져오기
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

# 모델 생성 및 학습
model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)
model.fit(x, y)
```




    LogisticRegression(C=10.0, random_state=0, solver='liblinear')




```python
# 모형 평가
p_pred = model.predict_proba(x)
print('p_pred', p_pred, sep ='\n')
```

    p_pred
    [[0.97979027 0.02020973]
     [0.94958202 0.05041798]
     [0.87976149 0.12023851]
     [0.73975066 0.26024934]
     [0.52477284 0.47522716]
     [0.30020373 0.69979627]
     [0.1428487  0.8571513 ]
     [0.06080627 0.93919373]
     [0.02453462 0.97546538]
     [0.00967652 0.99032348]]
    


```python
y_pred = model.predict(x)
print('y_pred', y_pred)
```

    y_pred [0 0 0 0 0 1 1 1 1 1]
    


```python
fig, ax = plt.subplots()
ax.scatter(x, y)
ax.plot(x, p_pred[:, 1], color = 'black',  marker='o', markersize=6)
ax.plot()

ax.set_xticks(x)
ax.set_yticks(np.arange(0, 1.1, 0.1))

ax.grid(which='major', alpha=0.5)
plt.show()
# y축 확률값, 1양성, 0음성, 검은 색이 각각의 확률값
```


    
![png](images/visualization_review/output_56_0.png)
    



```python
conf_m = confusion_matrix(y, y_pred)
print(conf_m)
```

    [[5 0]
     [0 5]]
    


```python
cm = confusion_matrix(y, y_pred)

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm, cmap = 'Pastel2')   # 색상 변경
# https://matplotlib.org/stable/tutorials/colors/colormaps.html
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0', 'Predicted 1'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0', 'Actual 1'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='black', fontsize=20)
plt.show()
```


    
![png](images/visualization_review/output_58_0.png)
    


### 결정 트리
- 분류와 회귀 문제에 모두 사용 가능

#### 주요 개념
- 작동 원리
  + 데이터를 가장 잘 구분하는 조건을 정함.
  + 조건을 기준으로 데이터를 두 범주로 나눔
  + 나뉜 각 범주의 데이터를 구분하는 조건을 정함
  + 각 조건을 기준으로 데이터를 두 범주로 나눔
  + 언제까지 계속 분할할지 정한 후, 최종 결정 값을 구함.
- 불순도(Impurity)
  + 한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지 나타냄
  + 흰색과 검은색이 50:50으로 섞여 있다. (불순도 최대)
  + 흰색과 검은색으로 완전 분리 되었다. (불순도 최소)
- 엔트로피(Entropy)
  + 불확실한 정도를 의미함. 0 ~ 1로 정함.
  + 흰색과 검은색이 50:50으로 섞여 있다. 엔트로피 1
  + 흰색과 검은색으로 완전 분리 되었다. 엔트로피 0
- 정보이득(Information Gain)
  + 1에서 엔트로피를 뺀 수치
  + 정보 이득을 최대화하는 방향(엔트로피를 최소화 하는 방향)으로 노드를 분할함
- 지니 불순도(Gini Impurity)
  + 지니 불순도 값이 클수록 불순도도 높고, 작을수록 불순도도 낮음. 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드 분할함.


```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split 
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')
titanic.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 15 columns):
     #   Column       Non-Null Count  Dtype   
    ---  ------       --------------  -----   
     0   survived     891 non-null    int64   
     1   pclass       891 non-null    int64   
     2   sex          891 non-null    object  
     3   age          714 non-null    float64 
     4   sibsp        891 non-null    int64   
     5   parch        891 non-null    int64   
     6   fare         891 non-null    float64 
     7   embarked     889 non-null    object  
     8   class        891 non-null    category
     9   who          891 non-null    object  
     10  adult_male   891 non-null    bool    
     11  deck         203 non-null    category
     12  embark_town  889 non-null    object  
     13  alive        891 non-null    object  
     14  alone        891 non-null    bool    
    dtypes: bool(2), category(2), float64(2), int64(4), object(5)
    memory usage: 80.7+ KB
    

- survived 생존자 비율을 구하자
  + 0: 사망자
  + 1: 생존자


```python
titanic['survived'].value_counts()
```




    0    549
    1    342
    Name: survived, dtype: int64




```python
# 데이터 추출
X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
```




    ((623, 3), (268, 3), (623,), (268,))




```python
tree_model = DecisionTreeClassifier()
tree_model.fit(X_train, y_train)

acc = tree_model.score(X_test, y_test)
print(f'모형 정확도 : {acc:.3f}') # 정확도 측정
```

    모형 정확도 : 0.672
    

### 랜덤 포레스트 = 디시젼 트리 (외워!@)


```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split 
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')

X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)

# 모델 훈련
rf_model = RandomForestClassifier(random_state=42) # 랜덤 포레스트 정의
rf_model.fit(X_train, y_train)

acc = rf_model.score(X_test, y_test)
print(f'모형 정확도 : {acc:.3f}') # 정확도 측정
```

    모형 정확도 : 0.675
    

# XGBoost & LightGBM (2016~2017)
- 전통적인 머신러닝 알고리즘의 융합
  + 선형회귀 릿지 라쏘 과적합 방지 위한 규제
  + 결정 트리의 핵심적인 알고리즘
  + 경사 하강법
- 문제점 : 파라미터의 개수가 매우 많음.
- 왜 많이 쓸까?
  + 모델 학습 속도
  + 성능
  + 가장 좋은 모델이란, 학습 속도는 빠르면서 성능은 좋은 것(지금까지 나온 알고리즘 보다)
- Python, JAVA
  + C, C++ / r data.table 패키지 또한 C, C++로 만들어짐
- 추측
  - 큰 회사들 개발
    + 첫번째 옵션, 우리가 자체적으로 배포하자. ->Python Wrapper API
      + R, 머신러닝 프레임워크 종류 다양
    + 두번째 옵션, 파이썬 머신러닝 = Scikit_Learn에서 쉽게 쓸 수 있도록 다시 개발, Scikit-Learn Wrapper API

## XGBoost Python Wrapper 방식
- X-train, y_train
- 각 모듈에 맞도록 행렬을 재변환 해야함.


```python
# 코드 차이점을 생각

import xgboost as xgb 
from sklearn.model_selection import train_test_split
import seaborn as sns 

# 데이터 분리
titanic = sns.load_dataset('titanic')
# titanic.info()

# X 독립변수, y 종속변수
X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    stratify = y, 
                                                    test_size = 0.3, 
                                                    random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
```




    ((623, 3), (268, 3), (623,), (268,))



### 별표 백개!!!!!
- 여기가 핵심
- X_train -> 사이킷런
- 여기에서 구분 가능


```python
# DMatrix ->파이썬래퍼 Wrapper 코드
dtrain=xgb.DMatrix(data = X_train, label =y_train)
dtest = xgb.DMatrix(data = X_test, label = y_test)

print(dtrain)
```

    <xgboost.core.DMatrix object at 0x7fb53e6dd090>
    

- 머신러닝 코드


```python
# from sklearn.tree~~이런게 없음
# xgb.train -> 파이썬 래퍼  Wrapper 코드
params = {
    'max_depth' : 3,
    'n_est imators' : 100,
    'eta' : 0.1,
    'objective' : 'binary:logistic'
}
num_rounds = 400  # 의사결정나무 에폭크와 비슷

w_list = [(dtrain, 'train'), (dtest, 'test')]
xgb_ml = xgb.train(params = params, 
                   dtrain = dtrain, 
                   num_boost_round = 400, 
                   early_stopping_rounds = 100, 
                   evals = w_list)
```

    [0]	train-error:0.260032	test-error:0.302239
    Multiple eval metrics have been passed: 'test-error' will be used for early stopping.
    
    Will train until test-error hasn't improved in 100 rounds.
    [1]	train-error:0.260032	test-error:0.302239
    [2]	train-error:0.260032	test-error:0.302239
    [3]	train-error:0.260032	test-error:0.302239
    [4]	train-error:0.260032	test-error:0.302239
    [5]	train-error:0.260032	test-error:0.302239
    [6]	train-error:0.260032	test-error:0.302239
    [7]	train-error:0.260032	test-error:0.302239
    [8]	train-error:0.260032	test-error:0.302239
    [9]	train-error:0.260032	test-error:0.302239
    [10]	train-error:0.260032	test-error:0.302239
    [11]	train-error:0.260032	test-error:0.302239
    [12]	train-error:0.260032	test-error:0.302239
    [13]	train-error:0.247191	test-error:0.298507
    [14]	train-error:0.247191	test-error:0.298507
    [15]	train-error:0.248796	test-error:0.302239
    [16]	train-error:0.248796	test-error:0.302239
    [17]	train-error:0.248796	test-error:0.302239
    [18]	train-error:0.248796	test-error:0.302239
    [19]	train-error:0.248796	test-error:0.302239
    [20]	train-error:0.248796	test-error:0.302239
    [21]	train-error:0.248796	test-error:0.302239
    [22]	train-error:0.248796	test-error:0.302239
    [23]	train-error:0.248796	test-error:0.302239
    [24]	train-error:0.248796	test-error:0.302239
    [25]	train-error:0.248796	test-error:0.302239
    [26]	train-error:0.248796	test-error:0.302239
    [27]	train-error:0.248796	test-error:0.302239
    [28]	train-error:0.247191	test-error:0.302239
    [29]	train-error:0.247191	test-error:0.302239
    [30]	train-error:0.247191	test-error:0.302239
    [31]	train-error:0.243981	test-error:0.298507
    [32]	train-error:0.247191	test-error:0.302239
    [33]	train-error:0.243981	test-error:0.298507
    [34]	train-error:0.243981	test-error:0.298507
    [35]	train-error:0.242376	test-error:0.294776
    [36]	train-error:0.24077	test-error:0.294776
    [37]	train-error:0.24077	test-error:0.294776
    [38]	train-error:0.24077	test-error:0.294776
    [39]	train-error:0.24077	test-error:0.294776
    [40]	train-error:0.24077	test-error:0.294776
    [41]	train-error:0.24077	test-error:0.294776
    [42]	train-error:0.24077	test-error:0.294776
    [43]	train-error:0.24077	test-error:0.294776
    [44]	train-error:0.24077	test-error:0.302239
    [45]	train-error:0.24077	test-error:0.302239
    [46]	train-error:0.24077	test-error:0.302239
    [47]	train-error:0.24077	test-error:0.302239
    [48]	train-error:0.24077	test-error:0.302239
    [49]	train-error:0.24077	test-error:0.302239
    [50]	train-error:0.24077	test-error:0.302239
    [51]	train-error:0.24077	test-error:0.302239
    [52]	train-error:0.23435	test-error:0.302239
    [53]	train-error:0.23435	test-error:0.302239
    [54]	train-error:0.232745	test-error:0.298507
    [55]	train-error:0.229535	test-error:0.298507
    [56]	train-error:0.229535	test-error:0.298507
    [57]	train-error:0.229535	test-error:0.298507
    [58]	train-error:0.229535	test-error:0.298507
    [59]	train-error:0.227929	test-error:0.294776
    [60]	train-error:0.227929	test-error:0.298507
    [61]	train-error:0.227929	test-error:0.298507
    [62]	train-error:0.227929	test-error:0.298507
    [63]	train-error:0.227929	test-error:0.298507
    [64]	train-error:0.227929	test-error:0.298507
    [65]	train-error:0.227929	test-error:0.298507
    [66]	train-error:0.227929	test-error:0.298507
    [67]	train-error:0.227929	test-error:0.298507
    [68]	train-error:0.227929	test-error:0.298507
    [69]	train-error:0.227929	test-error:0.298507
    [70]	train-error:0.227929	test-error:0.298507
    [71]	train-error:0.227929	test-error:0.298507
    [72]	train-error:0.227929	test-error:0.302239
    [73]	train-error:0.227929	test-error:0.302239
    [74]	train-error:0.229535	test-error:0.30597
    [75]	train-error:0.229535	test-error:0.30597
    [76]	train-error:0.229535	test-error:0.30597
    [77]	train-error:0.229535	test-error:0.30597
    [78]	train-error:0.229535	test-error:0.30597
    [79]	train-error:0.229535	test-error:0.30597
    [80]	train-error:0.229535	test-error:0.30597
    [81]	train-error:0.229535	test-error:0.30597
    [82]	train-error:0.229535	test-error:0.30597
    [83]	train-error:0.229535	test-error:0.30597
    [84]	train-error:0.229535	test-error:0.30597
    [85]	train-error:0.229535	test-error:0.30597
    [86]	train-error:0.229535	test-error:0.30597
    [87]	train-error:0.229535	test-error:0.30597
    [88]	train-error:0.229535	test-error:0.30597
    [89]	train-error:0.229535	test-error:0.30597
    [90]	train-error:0.229535	test-error:0.30597
    [91]	train-error:0.229535	test-error:0.30597
    [92]	train-error:0.229535	test-error:0.30597
    [93]	train-error:0.229535	test-error:0.30597
    [94]	train-error:0.227929	test-error:0.313433
    [95]	train-error:0.226324	test-error:0.313433
    [96]	train-error:0.223114	test-error:0.317164
    [97]	train-error:0.223114	test-error:0.317164
    [98]	train-error:0.223114	test-error:0.317164
    [99]	train-error:0.223114	test-error:0.317164
    [100]	train-error:0.223114	test-error:0.317164
    [101]	train-error:0.223114	test-error:0.317164
    [102]	train-error:0.223114	test-error:0.317164
    [103]	train-error:0.223114	test-error:0.317164
    [104]	train-error:0.223114	test-error:0.317164
    [105]	train-error:0.223114	test-error:0.317164
    [106]	train-error:0.223114	test-error:0.317164
    [107]	train-error:0.223114	test-error:0.317164
    [108]	train-error:0.223114	test-error:0.317164
    [109]	train-error:0.223114	test-error:0.317164
    [110]	train-error:0.223114	test-error:0.317164
    [111]	train-error:0.223114	test-error:0.317164
    [112]	train-error:0.223114	test-error:0.317164
    [113]	train-error:0.223114	test-error:0.317164
    [114]	train-error:0.223114	test-error:0.317164
    [115]	train-error:0.223114	test-error:0.317164
    [116]	train-error:0.223114	test-error:0.317164
    [117]	train-error:0.223114	test-error:0.317164
    [118]	train-error:0.223114	test-error:0.317164
    [119]	train-error:0.223114	test-error:0.317164
    [120]	train-error:0.223114	test-error:0.317164
    [121]	train-error:0.223114	test-error:0.317164
    [122]	train-error:0.223114	test-error:0.317164
    [123]	train-error:0.223114	test-error:0.317164
    [124]	train-error:0.224719	test-error:0.317164
    [125]	train-error:0.224719	test-error:0.317164
    [126]	train-error:0.224719	test-error:0.317164
    [127]	train-error:0.221509	test-error:0.317164
    [128]	train-error:0.223114	test-error:0.317164
    [129]	train-error:0.219904	test-error:0.313433
    [130]	train-error:0.215088	test-error:0.313433
    [131]	train-error:0.215088	test-error:0.313433
    [132]	train-error:0.215088	test-error:0.313433
    [133]	train-error:0.215088	test-error:0.313433
    [134]	train-error:0.215088	test-error:0.313433
    [135]	train-error:0.215088	test-error:0.313433
    Stopping. Best iteration:
    [35]	train-error:0.242376	test-error:0.294776
    
    


```python
# 평가
from sklearn.metrics import accuracy_score
pred_probs = xgb_ml.predict(dtest)
y_pred = [1 if x> 0.5 else 0 for x in pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred,y_test)
```




    0.6977611940298507



## XGBoost Scikit-Learn API 방식


```python
# from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier # API

# dt = DecisionTreeClassifier()
xgb_model = XGBClassifier(objestive = 'binary:logistic',
                          n_estimators=100,
                          max_depth=3,
                          learning_rate = 0.1,
                          num_rounds = 400,
                          random_state=42)

w_list = [(X_train, y_train), (X_test, y_test)]
xgb_model.fit(X_train, y_train, eval_set = w_list, eval_metric= 'error', verbose=True)

y_probas = xgb_model.predict_proba(X_test)
y_pred = [1 if x> 0.5 else 0 for x in pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred,y_test)
```

    [0]	validation_0-error:0.260032	validation_1-error:0.302239
    [1]	validation_0-error:0.260032	validation_1-error:0.302239
    [2]	validation_0-error:0.260032	validation_1-error:0.302239
    [3]	validation_0-error:0.260032	validation_1-error:0.302239
    [4]	validation_0-error:0.260032	validation_1-error:0.302239
    [5]	validation_0-error:0.260032	validation_1-error:0.302239
    [6]	validation_0-error:0.260032	validation_1-error:0.302239
    [7]	validation_0-error:0.260032	validation_1-error:0.302239
    [8]	validation_0-error:0.260032	validation_1-error:0.302239
    [9]	validation_0-error:0.260032	validation_1-error:0.302239
    [10]	validation_0-error:0.260032	validation_1-error:0.302239
    [11]	validation_0-error:0.260032	validation_1-error:0.302239
    [12]	validation_0-error:0.260032	validation_1-error:0.302239
    [13]	validation_0-error:0.247191	validation_1-error:0.298507
    [14]	validation_0-error:0.247191	validation_1-error:0.298507
    [15]	validation_0-error:0.248796	validation_1-error:0.302239
    [16]	validation_0-error:0.248796	validation_1-error:0.302239
    [17]	validation_0-error:0.248796	validation_1-error:0.302239
    [18]	validation_0-error:0.248796	validation_1-error:0.302239
    [19]	validation_0-error:0.248796	validation_1-error:0.302239
    [20]	validation_0-error:0.248796	validation_1-error:0.302239
    [21]	validation_0-error:0.248796	validation_1-error:0.302239
    [22]	validation_0-error:0.248796	validation_1-error:0.302239
    [23]	validation_0-error:0.248796	validation_1-error:0.302239
    [24]	validation_0-error:0.248796	validation_1-error:0.302239
    [25]	validation_0-error:0.248796	validation_1-error:0.302239
    [26]	validation_0-error:0.248796	validation_1-error:0.302239
    [27]	validation_0-error:0.248796	validation_1-error:0.302239
    [28]	validation_0-error:0.247191	validation_1-error:0.302239
    [29]	validation_0-error:0.247191	validation_1-error:0.302239
    [30]	validation_0-error:0.247191	validation_1-error:0.302239
    [31]	validation_0-error:0.243981	validation_1-error:0.298507
    [32]	validation_0-error:0.247191	validation_1-error:0.302239
    [33]	validation_0-error:0.243981	validation_1-error:0.298507
    [34]	validation_0-error:0.243981	validation_1-error:0.298507
    [35]	validation_0-error:0.242376	validation_1-error:0.294776
    [36]	validation_0-error:0.24077	validation_1-error:0.294776
    [37]	validation_0-error:0.24077	validation_1-error:0.294776
    [38]	validation_0-error:0.24077	validation_1-error:0.294776
    [39]	validation_0-error:0.24077	validation_1-error:0.294776
    [40]	validation_0-error:0.24077	validation_1-error:0.294776
    [41]	validation_0-error:0.24077	validation_1-error:0.294776
    [42]	validation_0-error:0.24077	validation_1-error:0.294776
    [43]	validation_0-error:0.24077	validation_1-error:0.294776
    [44]	validation_0-error:0.24077	validation_1-error:0.302239
    [45]	validation_0-error:0.24077	validation_1-error:0.302239
    [46]	validation_0-error:0.24077	validation_1-error:0.302239
    [47]	validation_0-error:0.24077	validation_1-error:0.302239
    [48]	validation_0-error:0.24077	validation_1-error:0.302239
    [49]	validation_0-error:0.24077	validation_1-error:0.302239
    [50]	validation_0-error:0.24077	validation_1-error:0.302239
    [51]	validation_0-error:0.24077	validation_1-error:0.302239
    [52]	validation_0-error:0.23435	validation_1-error:0.302239
    [53]	validation_0-error:0.23435	validation_1-error:0.302239
    [54]	validation_0-error:0.232745	validation_1-error:0.298507
    [55]	validation_0-error:0.229535	validation_1-error:0.298507
    [56]	validation_0-error:0.229535	validation_1-error:0.298507
    [57]	validation_0-error:0.229535	validation_1-error:0.298507
    [58]	validation_0-error:0.229535	validation_1-error:0.298507
    [59]	validation_0-error:0.227929	validation_1-error:0.294776
    [60]	validation_0-error:0.227929	validation_1-error:0.298507
    [61]	validation_0-error:0.227929	validation_1-error:0.298507
    [62]	validation_0-error:0.227929	validation_1-error:0.298507
    [63]	validation_0-error:0.227929	validation_1-error:0.298507
    [64]	validation_0-error:0.227929	validation_1-error:0.298507
    [65]	validation_0-error:0.227929	validation_1-error:0.298507
    [66]	validation_0-error:0.227929	validation_1-error:0.298507
    [67]	validation_0-error:0.227929	validation_1-error:0.298507
    [68]	validation_0-error:0.227929	validation_1-error:0.298507
    [69]	validation_0-error:0.227929	validation_1-error:0.298507
    [70]	validation_0-error:0.227929	validation_1-error:0.298507
    [71]	validation_0-error:0.227929	validation_1-error:0.298507
    [72]	validation_0-error:0.227929	validation_1-error:0.302239
    [73]	validation_0-error:0.227929	validation_1-error:0.302239
    [74]	validation_0-error:0.229535	validation_1-error:0.30597
    [75]	validation_0-error:0.229535	validation_1-error:0.30597
    [76]	validation_0-error:0.229535	validation_1-error:0.30597
    [77]	validation_0-error:0.229535	validation_1-error:0.30597
    [78]	validation_0-error:0.229535	validation_1-error:0.30597
    [79]	validation_0-error:0.229535	validation_1-error:0.30597
    [80]	validation_0-error:0.229535	validation_1-error:0.30597
    [81]	validation_0-error:0.229535	validation_1-error:0.30597
    [82]	validation_0-error:0.229535	validation_1-error:0.30597
    [83]	validation_0-error:0.229535	validation_1-error:0.30597
    [84]	validation_0-error:0.229535	validation_1-error:0.30597
    [85]	validation_0-error:0.229535	validation_1-error:0.30597
    [86]	validation_0-error:0.229535	validation_1-error:0.30597
    [87]	validation_0-error:0.229535	validation_1-error:0.30597
    [88]	validation_0-error:0.229535	validation_1-error:0.30597
    [89]	validation_0-error:0.229535	validation_1-error:0.30597
    [90]	validation_0-error:0.229535	validation_1-error:0.30597
    [91]	validation_0-error:0.229535	validation_1-error:0.30597
    [92]	validation_0-error:0.229535	validation_1-error:0.30597
    [93]	validation_0-error:0.229535	validation_1-error:0.30597
    [94]	validation_0-error:0.227929	validation_1-error:0.313433
    [95]	validation_0-error:0.226324	validation_1-error:0.313433
    [96]	validation_0-error:0.223114	validation_1-error:0.317164
    [97]	validation_0-error:0.223114	validation_1-error:0.317164
    [98]	validation_0-error:0.223114	validation_1-error:0.317164
    [99]	validation_0-error:0.223114	validation_1-error:0.317164
    




    0.6977611940298507



## Light GBM Python Wrapper 방식


```python
import lightgbm as lgb 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')

X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)

# XGBoost 코드와 유사하다. 
dtrain = lgb.Dataset(data = X_train, label = y_train)
dtest = lgb.Dataset(data = X_test, label = y_test)

params = {'max_depth':3,
          'n_estimators':100,
          'learning_rate': 0.1,
          'objective':'binary',
          'metric' : 'binary_error', 
          'num_boost_round' : 400, 
          'verbose' : 1} 

w_list = [dtrain, dtest]
lgb_ml = lgb.train(params=params, train_set = dtrain,\
                  early_stopping_rounds=100, valid_sets= w_list)

pred_probs = lgb_ml.predict(X_test)
y_pred=[1 if x > 0.5 else 0 for x in pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```

    /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
      warnings.warn("Found `{}` in params. Will use it instead of argument".format(alias))
    

    [1]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    Training until validation scores don't improve for 100 rounds.
    [2]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    [3]	training's binary_error: 0.354735	valid_1's binary_error: 0.369403
    [4]	training's binary_error: 0.29695	valid_1's binary_error: 0.354478
    [5]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [6]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [7]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [8]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [9]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [10]	training's binary_error: 0.269663	valid_1's binary_error: 0.309701
    [11]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [12]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [13]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [14]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [15]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [16]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [17]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [18]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [19]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [20]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [21]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [22]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [23]	training's binary_error: 0.271268	valid_1's binary_error: 0.313433
    [24]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [25]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [26]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [27]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [28]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [29]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [30]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [31]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [32]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [33]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [34]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [35]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [36]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [37]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [38]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [39]	training's binary_error: 0.248796	valid_1's binary_error: 0.309701
    [40]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [41]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [42]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [43]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [44]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [45]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [46]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [47]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [48]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [49]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [50]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [51]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [52]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [53]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [54]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [55]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [56]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [57]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [58]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [59]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [60]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [61]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [62]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [63]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [64]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [65]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [66]	training's binary_error: 0.243981	valid_1's binary_error: 0.309701
    [67]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [68]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [69]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [70]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [71]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [72]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [73]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [74]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [75]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [76]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [77]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [78]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [79]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [80]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [81]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [82]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [83]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [84]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [85]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [86]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [87]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [88]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [89]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [90]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [91]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [92]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [93]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [94]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [95]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [96]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [97]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [98]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [99]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [100]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [102]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [103]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [104]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [105]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [106]	training's binary_error: 0.224719	valid_1's binary_error: 0.313433
    [107]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [108]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [109]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [110]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [111]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [112]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [113]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [114]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [115]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [116]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [117]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [118]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [119]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [120]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [121]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [122]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [123]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [124]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [125]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [126]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [127]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [128]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [129]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [130]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [131]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [132]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [133]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [134]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [135]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [136]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [137]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [138]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [139]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [140]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [141]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [142]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [143]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [144]	training's binary_error: 0.221509	valid_1's binary_error: 0.320896
    [145]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [146]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [147]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [148]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [149]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [150]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [151]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [152]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [153]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [154]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [155]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [156]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [157]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [158]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [159]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [160]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [161]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [162]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [163]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [164]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [165]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [166]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [167]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [168]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [169]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [170]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [171]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [172]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [173]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [174]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [175]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [176]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [177]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [178]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [179]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [180]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [181]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [182]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [183]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [184]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [185]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [186]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [187]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [188]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [189]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [190]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [191]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [192]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [193]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [194]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [195]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [196]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [197]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [198]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [199]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [200]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [201]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    Early stopping, best iteration is:
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    




    0.6940298507462687



## Light GBM Scikit-Learn API 방식


```python
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score

# model 
w_list = [dtrain, dtest]
model = LGBMClassifier(objective = 'binary', 
                       metric = 'binary_error',
                       n_estimators=100, 
                       learning_rate=0.1, 
                       max_depth=3, 
                       num_boost_round = 400,
                       random_state = 32)
model.fit(X_train, 
          y_train, 
          eval_set = [(X_train, y_train), (X_test, y_test)], 
          verbose=1,
          early_stopping_rounds = 100)
y_probas = model.predict_proba(X_test) 
y_pred=[1 if x > 0.5 else 0 for x in y_probas[:, 1]] # 예측 라벨(0과 1로 예측)

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```

    /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
      warnings.warn("Found `{}` in params. Will use it instead of argument".format(alias))
    

    [1]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    Training until validation scores don't improve for 100 rounds.
    [2]	training's binary_error: 0.383628	valid_1's binary_error: 0.384328
    [3]	training's binary_error: 0.354735	valid_1's binary_error: 0.369403
    [4]	training's binary_error: 0.29695	valid_1's binary_error: 0.354478
    [5]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [6]	training's binary_error: 0.272873	valid_1's binary_error: 0.33209
    [7]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [8]	training's binary_error: 0.269663	valid_1's binary_error: 0.317164
    [9]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [10]	training's binary_error: 0.269663	valid_1's binary_error: 0.309701
    [11]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [12]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [13]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [14]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [15]	training's binary_error: 0.264848	valid_1's binary_error: 0.309701
    [16]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [17]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [18]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [19]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [20]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [21]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [22]	training's binary_error: 0.266453	valid_1's binary_error: 0.313433
    [23]	training's binary_error: 0.271268	valid_1's binary_error: 0.313433
    [24]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [25]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [26]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [27]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [28]	training's binary_error: 0.258427	valid_1's binary_error: 0.309701
    [29]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [30]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [31]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [32]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [33]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [34]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [35]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [36]	training's binary_error: 0.255217	valid_1's binary_error: 0.309701
    [37]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [38]	training's binary_error: 0.255217	valid_1's binary_error: 0.317164
    [39]	training's binary_error: 0.248796	valid_1's binary_error: 0.309701
    [40]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [41]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [42]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [43]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [44]	training's binary_error: 0.248796	valid_1's binary_error: 0.313433
    [45]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [46]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [47]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [48]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [49]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [50]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [51]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [52]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [53]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [54]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [55]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [56]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [57]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [58]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [59]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [60]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [61]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [62]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [63]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [64]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [65]	training's binary_error: 0.247191	valid_1's binary_error: 0.313433
    [66]	training's binary_error: 0.243981	valid_1's binary_error: 0.309701
    [67]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [68]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [69]	training's binary_error: 0.23435	valid_1's binary_error: 0.309701
    [70]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [71]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [72]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [73]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [74]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [75]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [76]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [77]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [78]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [79]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [80]	training's binary_error: 0.232745	valid_1's binary_error: 0.313433
    [81]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [82]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [83]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [84]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [85]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [86]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [87]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [88]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [89]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [90]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [91]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [92]	training's binary_error: 0.229535	valid_1's binary_error: 0.309701
    [93]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [94]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [95]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [96]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [97]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [98]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [99]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [100]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [102]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    [103]	training's binary_error: 0.227929	valid_1's binary_error: 0.309701
    [104]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [105]	training's binary_error: 0.221509	valid_1's binary_error: 0.317164
    [106]	training's binary_error: 0.224719	valid_1's binary_error: 0.313433
    [107]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [108]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [109]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [110]	training's binary_error: 0.224719	valid_1's binary_error: 0.317164
    [111]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [112]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [113]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [114]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [115]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [116]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [117]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [118]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [119]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [120]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [121]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [122]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [123]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [124]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [125]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [126]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [127]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [128]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [129]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [130]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [131]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [132]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [133]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [134]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [135]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [136]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [137]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [138]	training's binary_error: 0.219904	valid_1's binary_error: 0.309701
    [139]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [140]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [141]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [142]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [143]	training's binary_error: 0.223114	valid_1's binary_error: 0.309701
    [144]	training's binary_error: 0.221509	valid_1's binary_error: 0.320896
    [145]	training's binary_error: 0.223114	valid_1's binary_error: 0.313433
    [146]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [147]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [148]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [149]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [150]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [151]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [152]	training's binary_error: 0.221509	valid_1's binary_error: 0.313433
    [153]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [154]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [155]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [156]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [157]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [158]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [159]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [160]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [161]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [162]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [163]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [164]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [165]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [166]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [167]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [168]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [169]	training's binary_error: 0.219904	valid_1's binary_error: 0.324627
    [170]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [171]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [172]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [173]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [174]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [175]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [176]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [177]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [178]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [179]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [180]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [181]	training's binary_error: 0.221509	valid_1's binary_error: 0.328358
    [182]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [183]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [184]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [185]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [186]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [187]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [188]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [189]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [190]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [191]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [192]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [193]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [194]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [195]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [196]	training's binary_error: 0.216693	valid_1's binary_error: 0.320896
    [197]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [198]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [199]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [200]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    [201]	training's binary_error: 0.215088	valid_1's binary_error: 0.317164
    Early stopping, best iteration is:
    [101]	training's binary_error: 0.23114	valid_1's binary_error: 0.30597
    




    0.6940298507462687


